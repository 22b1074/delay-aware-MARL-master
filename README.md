# ğŸ¤– FD-MADDPG: Fractional Delay-Aware Multi-Agent Reinforcement Learning

> **Novel extension of DAMA-DDPG to handle non-integer timestep delays via Virtual Effective Actions (VEA)**

---

## ğŸ¯ TL;DR

We extended delay-aware MARL from **integer-only delays** â†’ **fractional/continuous delays**, enabling discrete RL systems to approximate continuous-time behavior. Our method performs **on par with integer-delay baselines** while handling realistic, non-integer latencies.

---

## ğŸ§  The Problem

| Existing Approaches | Our Solution |
|---------------------|--------------|
| DAMA-DDPG handles only integer delays (1, 2, 3...) | Supports fractional delays (1.7, 2.3, etc.) |
| Real-world systems have continuous latencies | Linear interpolation bridges discrete timesteps |
| No mechanism to approximate between timesteps | Virtual Effective Actions (VEA) blend past actions |

---

## ğŸ’¡ Key Innovation: Virtual Effective Actions

For a fractional delay `d = I + f` where `f âˆˆ [0,1)`:

```
Ã£_t = (1 - f) Â· a_{t-I} + f Â· a_{t-(I+1)}
```

**Translation:** Instead of picking ONE past action, we *blend* two consecutive actions proportionally â€” simulating what would happen if the action arrived "in between" timesteps.

---

## ğŸ“Š Results Summary

| Model | Delay | Performance |
|-------|-------|-------------|
| Delay-Unaware MADDPG | â€” | âŒ Unstable, slow convergence |
| Integer-Delay MARL | 1, 2 | âœ… Stable, good rewards |
| **FD-MADDPG (Ours)** | 1.7, 2.7 | âœ… **Matches integer-delay performance** |

*Tested on PettingZoo's `simple_spread_v3` with 3 cooperative agents over 10K-30K episodes.*

---

## ğŸ”§ Implementation Highlights

- **Extended MADDPG** with action buffers for delay tracking
- **Custom environment wrappers** â€” migrated from deprecated MPE to PettingZoo's latest API
- **Linear interpolation module** for computing virtual effective actions
- **Centralized Training, Decentralized Execution (CTDE)** paradigm

---

## ğŸ“ˆ Training Curves

- **Non-integral delay (ours)** performs **on par with integral delay-aware** models
- Both delay-aware approaches significantly outperform delay-unaware baseline
- Delay-unaware training shows **unstable learning** with high variance and slower convergence

---
---

## ğŸ”‘ Key Takeaways

- âœ… Fractional delay handling via interpolation **works** â€” no performance degradation vs integer delays
- âœ… Provides smooth bridge from **discrete â†’ continuous** delay modeling
- âœ… Drop-in compatible with existing MADDPG implementations
- âœ… Updated for **PettingZoo v3** (latest multi-agent env standard)

---

## ğŸ“š References

- Chen et al. (2020) â€” *Delay-Aware Multi-Agent RL for Cooperative and Competitive Environments*
- Lowe et al. (2017) â€” *Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments*
- Hou & Phoha (2010) â€” *Control Delay in RL for Real-Time Dynamic Systems*

---


---

*Bridging the gap between theoretical discrete-time MARL and real-world continuous delays.*
